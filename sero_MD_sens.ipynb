{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from pandas.api.indexers import FixedForwardWindowIndexer\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax.numpy import array as arr\n",
    "from jax import lax, random\n",
    "from jax.experimental.ode import odeint\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.scipy.special import expit as logistic\n",
    "from jax.scipy.special import logit\n",
    "from jax.scipy.special import gammaln\n",
    "from jax.scipy import stats\n",
    "\n",
    "import numpyro as pn\n",
    "from numpyro import sample\n",
    "from numpyro import deterministic\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.distributions import Normal as Norm\n",
    "from numpyro.distributions import Exponential as Ex\n",
    "from numpyro.distributions import Poisson as Pois\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "from numpyro.diagnostics import print_summary, hpdi\n",
    "\n",
    "from scipy.interpolate import BSpline\n",
    "import numpy as num ##scipy needs actual numpy\n",
    "\n",
    "import warnings\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = [\"svg\"]\n",
    "plt.style.use(\"default\")\n",
    "sns.set_theme(context='paper', style=\"ticks\", font_scale=1.25)\n",
    "warnings.formatwarning = lambda message, category, *args, **kwargs: \"{}: {}\\n\".format(category.__name__, message)\n",
    "\n",
    "## set numpyro platform to cpu because I don't have the right kind of gpu\n",
    "pn.set_platform(\"cpu\")\n",
    "\n",
    "## tell numpyro to use mult cpu cores (this many chains can run in parallel)\n",
    "pn.set_host_device_count(4)\n",
    "\n",
    "## jax wants float32's by default, but sometimes it helps to use higher-precision floats:\n",
    "HIPREC = True\n",
    "\n",
    "if HIPREC: \n",
    "    pn.enable_x64()\n",
    "    fl = np.float64\n",
    "    toint = np.int64\n",
    "else:\n",
    "    fl = np.float32\n",
    "    toint = np.int32\n",
    "\n",
    "## for jax's RNG\n",
    "def key_gen(seed = random.PRNGKey(8927)):\n",
    "    def key():\n",
    "        nonlocal seed\n",
    "        seed, new_key = random.split(seed)\n",
    "        return new_key\n",
    "    return key\n",
    "\n",
    "key = key_gen()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(obj, name):\n",
    "    with open(f'{name}.dill', 'wb') as f:\n",
    "        dill.dump(obj, f)\n",
    "\n",
    "def load(name):\n",
    "    with open(f'{name}.dill', 'rb') as f:\n",
    "        return dill.load(f)\n",
    "\n",
    "#def pdz(series):\n",
    "#    return (series - series.mean()) / series.std()\n",
    "\n",
    "## resizes an array, repeating the last element if needed\n",
    "#def resize(x, new_size):\n",
    "#    return np.concatenate([x,np.repeat(x[-1], max(0,new_size-len(x)))])[:new_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SECIR_ode(y, t, p):\n",
    "    S, E, C, I, R, CumC, CumI = y[0], y[1], y[2], y[3], y[4], y[5], y[6]\n",
    "    alpha, beta, mu, gamma1, gamma2, theta = p[0], p[1], p[2], p[3], p[4], p[5]\n",
    "    N = S + E + C + I + R\n",
    "    S_dot = -S*C*alpha*beta/N - S*I*beta/N\n",
    "    E_dot = S*C*alpha*beta/N + S*I*beta/N - E*mu\n",
    "    C_dot = E*mu*(1-theta) - C*gamma1\n",
    "    I_dot = E*mu*theta - I*gamma2\n",
    "    R_dot = C*gamma1 + I*gamma2\n",
    "    CumC_dot = E*mu*(1-theta)\n",
    "    CumI_dot = E*mu*theta\n",
    "    return np.stack([S_dot, E_dot, C_dot, I_dot, R_dot, CumC_dot, CumI_dot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## have to do time-variable ODE params this way\n",
    "##  then, jax.lax.scan(onestep, y0, p_t)[1]\n",
    "## scan() will pass each param set in p_t to onestep() and collect the results in return value [1]\n",
    "## p_t must have time as the first axis\n",
    "def onestep(prev, p):\n",
    "    next = odeint(SECIR_ode, prev, arr([0.,1.]), p, rtol=1e-6, atol=1e-6, mxstep=2000)#rtol=1e-6, atol=1e-6, mxstep=1000)#rtol=1e-5, atol=1e-5, mxstep=500)\n",
    "    return next[1], next[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this way works fine by itself, but not inside the sampler\n",
    "##  for some incomprehensible reason\n",
    "def SECIR_ode_t(y, t, p):\n",
    "    S, E, C, I, R, CumC, CumI = y[0], y[1], y[2], y[3], y[4], y[5], y[6]\n",
    "    idx = toint(t)\n",
    "    alpha, beta, mu, gamma1, gamma2, theta = p[0][idx], p[1][idx], p[2][idx], p[3][idx], p[4][idx], p[5][idx]\n",
    "    N = S + E + C + I + R\n",
    "    S_dot = -S*C*alpha*beta/N - S*I*beta/N\n",
    "    E_dot = S*C*alpha*beta/N + S*I*beta/N - E*mu\n",
    "    C_dot = E*mu*(1-theta) - C*gamma1\n",
    "    I_dot = E*mu*theta - I*gamma2\n",
    "    R_dot = C*gamma1 + I*gamma2\n",
    "    CumC_dot = E*mu*(1-theta)\n",
    "    CumI_dot = E*mu*theta\n",
    "    return np.stack([S_dot, E_dot, C_dot, I_dot, R_dot, CumC_dot, CumI_dot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R = (th)(b / g2) + (a)(1-th)(b / g1)\n",
    "\n",
    "## R*g1*g2 =  b * [ th*g1 + a(1-th)*g2 ] \n",
    "\n",
    "## b = R*g1*g2 / [ th*g1 + a(1-th)*g2 ]\n",
    "\n",
    "def calc_R(b, g1, g2, th, a = 1.0):\n",
    "    return th*(b / g2) + a*(1.0-th)*(b / g1)\n",
    "\n",
    "def calc_b(R, g1, g2, th, a = 1.0):\n",
    "    return R*g1*g2 / ( th*g1 + a*(1.0-th)*g2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pred_daily_samp(post, modeldict, n_draws, full_reporting=False):\n",
    "    res = []\n",
    "    psize = modeldict['Population']\n",
    "    nsamples = post['sigma'].shape[0]\n",
    "    samp_ids = jax.random.permutation(key(),nsamples,independent=True)[:n_draws]\n",
    "    for s in samp_ids:\n",
    "        b0, th0 = post['beta'][s], post['theta'][s]\n",
    "        if full_reporting:\n",
    "            th0 = np.ones_like(th0)\n",
    "        a0,mu0,g1,g2 = post['alpha'][s], post['mu'][s], post['gamma1'][s], post['gamma2'][s]\n",
    "        e0,i0,c0 = post['e0'][s], post['i0'][s], post['c0'][s]\n",
    "        y0 = arr([psize - (e0 + c0 + i0), e0, c0, i0, c0*0.0, c0, i0])\n",
    "        p_t = np.stack([a0 , b0 , mu0 , g1, g2, th0]).T #time first\n",
    "        pred_vals = jax.lax.scan(onestep, y0, p_t)[1]\n",
    "        pred_daily = np.diff(pred_vals[:,6], prepend=0)\n",
    "        res.append(pred_daily)\n",
    "\n",
    "    return np.stack(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_samples(post, modeldict, real_R_calc = False):\n",
    "    df = pd.DataFrame({\"Date\":modeldict[\"Dates\"]})\n",
    "\n",
    "    if real_R_calc:\n",
    "        R_t = calc_R(post['beta'], post['gamma1'], post['gamma2'], post['theta'], post['alpha'])\n",
    "    else:\n",
    "        R_t = post['beta'] / post['gamma2']\n",
    "\n",
    "    df[\"R_t\"] = R_t.mean(0)\n",
    "    ci = hpdi(R_t)\n",
    "    df[\"R_t_lower95\"] = ci[0,:]\n",
    "    df[\"R_t_upper95\"] = ci[1,:]\n",
    "    df['DailyCases'] = modeldict['DailyCases']\n",
    "    df['theta'] = post['theta'].mean(0)\n",
    "    cols = []\n",
    "    pred_daily = pred_daily_samp(post, modeldict, 50)\n",
    "    for i,v in enumerate(pred_daily):\n",
    "        colname = 'sim'+str(i)\n",
    "        df[colname] = v\n",
    "        cols.append(colname)\n",
    "\n",
    "    return df, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data from MD dept of health\n",
    "MD_cases = pd.read_csv(\"MDCOVID19_TotalCasesStatewide.csv\")\n",
    "MD_cases[\"daily\"] = np.diff(MD_cases[\"Count_\"].values, prepend=0)\n",
    "\n",
    "## forward-looking moving average, because reporting is always in the future\n",
    "f7_indexer = FixedForwardWindowIndexer(window_size=7)\n",
    "\n",
    "#MD_cases[\"MD_CumCases\"] = MD_cases[\"Count_\"].rolling(f7_indexer, min_periods=1).mean()\n",
    "MD_cases[\"MD_DailyCases\"] = MD_cases[\"daily\"].rolling(f7_indexer, min_periods=1).mean()\n",
    "MD_cases[\"Date\"] = MD_cases[\"DATE\"].apply(lambda x: str.split(x)[0].replace('/','-'))\n",
    "MD_cases = MD_cases.loc[0:453,[\"Date\",\"MD_DailyCases\"]]\n",
    "MD_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_MD = MD_cases[\"MD_DailyCases\"] < 0.0\n",
    "MD_cases.loc[bad_MD,\"MD_DailyCases\"] = np.nan\n",
    "md_data_ok = np.logical_not(bad_MD.values)\n",
    "bad_MD.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(MD_cases[\"MD_DailyCases\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## serology data from JHU\n",
    "sero_results = pd.read_csv('TestResultsByDateWithWeights.csv')\n",
    "## overall weight of each data point\n",
    "sero_results['wt'] = sero_results['hwght'] * sero_results['psuweight']\n",
    "sero_results['weight'] = (sero_results[\"wt\"] / sero_results[\"wt\"].mean())\n",
    "sero_results['dt'] = pd.to_datetime(sero_results['Specimen_collection_date']).apply(str)\n",
    "sero_results['Date'] = sero_results['dt'].apply(lambda x: str.split(x)[0].replace('/','-'))\n",
    "## match date index to case data\n",
    "date_idxs = pd.DataFrame({\"Date\":MD_cases[\"Date\"], \"date_idx_raw\":range(len(MD_cases[\"Date\"]))})\n",
    "sero_results = sero_results.merge(date_idxs,how=\"left\",on=\"Date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## assume ## (ref=14) days from symptom onset to seroconversion\n",
    "seroconv_lag = 21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## map each sero result to the infection count from seroconv_lag days prior\n",
    "sero_results[\"date_idx\"] = sero_results[\"date_idx_raw\"] - seroconv_lag\n",
    "\n",
    "sero_results = sero_results[[\"Date\",\"date_idx\",\"seropos\",\"weight\"]]\n",
    "sero_results = sero_results.sort_values(by=\"date_idx\")\n",
    "sero_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MD deaths from dept health\n",
    "dd = pd.read_csv('MDCOVID19_TotalConfirmedDeathsByDateOfDeath.csv')\n",
    "dd['Date'] = dd['DATE'].apply(lambda x: str.split(x)[0].replace('/','-'))\n",
    "MD_deaths = MD_cases[[\"Date\"]].merge(dd[[\"Date\",\"Count_\"]],how=\"outer\",on=\"Date\").fillna(0.0)\n",
    "## forward-looking moving average, because reporting is always in the future\n",
    "MD_deaths['daily_deaths']  = MD_deaths[\"Count_\"].rolling(f7_indexer, min_periods=1).mean()\n",
    "MD_deaths = MD_deaths[[\"Date\",\"daily_deaths\"]]\n",
    "MD_deaths.set_index('Date',verify_integrity=True,inplace=True)\n",
    "MD_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(MD_deaths['daily_deaths'].values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_obs = arr(MD_cases['MD_DailyCases'].values)\n",
    "ts = np.arange(fl(len(daily_obs)))\n",
    "daily_ok_raw = daily_obs[md_data_ok]\n",
    "totalI = np.sum(daily_ok_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## splines\n",
    "## evenly spaced basis splines, approx 14 day period\n",
    "n_spline_periods = 32 \n",
    "deg = 2\n",
    "knots = num.linspace(0., ts.max(), n_spline_periods+1-deg)\n",
    "padded_knots = num.pad(knots, (deg,deg), mode='edge')\n",
    "B = BSpline(padded_knots, num.identity(len(knots)+deg-1), deg)(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MD_dict = {\n",
    "    'tdom': ts,\n",
    "    'Dates': MD_cases[\"Date\"].values,\n",
    "    'initInfected': 1.0, ## I compartment only; C compartment estimated by model\n",
    "    'Population': 6177224.0, ## from US census ## 6045680.0, ## from ???\n",
    "    'alpha': np.repeat(1.0, len(ts)),\n",
    "    'mu': np.repeat(0.15, len(ts)), ## incubation 6.65 days ref Wu 2022\n",
    "    'gamma1': np.repeat(0.2, len(ts)), ## infectiousness period ~5 days ref Bi 2020 and Giardina 2021\n",
    "    'gamma2': np.repeat(0.2, len(ts)),\n",
    "    'DailyCases': daily_obs,\n",
    "    'totalI': totalI,\n",
    "    'daily_ok': daily_ok_raw / totalI,\n",
    "    'Nt': len(daily_ok_raw),\n",
    "    'knots': arr(knots),\n",
    "    'spline': arr(B),\n",
    "    'nperiods': n_spline_periods,\n",
    "    'sero_date_idxs': arr(sero_results[\"date_idx\"].values),\n",
    "    'seropos': arr(sero_results[\"seropos\"].values),\n",
    "    'sero_weights': arr(sero_results[\"weight\"].values)\n",
    "}\n",
    "\n",
    "ok_for_jax = md_data_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the splines:\n",
    "_,ax = plt.subplots(figsize=[12,3])\n",
    "ax.set_xticks(np.linspace(0,len(MD_dict['tdom']),MD_dict['nperiods']+1))\n",
    "for i in range(MD_dict['nperiods']):\n",
    "    plt.plot(MD_dict['spline'][:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rev_L = 202.2\n",
    "#rev_k = 2.32\n",
    "#rev_curve = np.flip(np.exp(-np.power( np.arange(300.) /rev_L, rev_k)))\n",
    "#rev_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rev_mat = np.flip( jax.lax.map(lambda i: np.roll(rev_curve,i), -1*np.arange(300)) , axis=0 ) * np.tri(300)\n",
    "#rev_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = dist.Beta(0.20,2.0).sample(key(),(10000,))\n",
    "az.plot_kde(samp, quantiles=[0.25,0.5,0.75]);\n",
    "print(hpdi(samp), np.mean(samp), np.median(samp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = dist.Gamma(3.0,0.1).sample(key(),(10000,))\n",
    "az.plot_kde(samp, quantiles=[0.25,0.5,0.75]);\n",
    "print(hpdi(samp), np.mean(samp), np.median(samp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = dist.LogNormal(0.0,0.7071).sample(key(),(10000,))\n",
    "az.plot_kde(samp, quantiles=[0.25,0.5,0.75]);\n",
    "print(hpdi(samp), np.mean(samp), np.median(samp), np.std(samp), sum(samp<0.5), sum(samp>2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax=plt.subplots()\n",
    "ax.set(ylim=(0,1))\n",
    "th_max = 0.6\n",
    "th0s = arr([-2.0,-4.0])\n",
    "shapes = arr([0.5,1.0,2.0])\n",
    "dth_dt = 0.05\n",
    "for th0 in th0s:\n",
    "    for shape in shapes:\n",
    "        #ax.plot(MD_dict['tdom'], th_max * logistic(th0 + MD_dict['tdom']*dth_dt))\n",
    "        ax.plot(MD_dict['tdom'], th_max * np.power(1.0 + np.exp(-th0 - MD_dict['tdom']*dth_dt), -shape) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_conc = 5.\n",
    "beta_n = 1.0 + 0.2 * (0.0 + beta_conc)\n",
    "samp = 5.0 * dist.Gamma(beta_n,beta_conc).sample(key(),(50000,))\n",
    "az.plot_kde(samp, quantiles=[0.25,0.5,0.75]);\n",
    "print(hpdi(samp,prob=0.95), np.mean(samp), np.median(samp), np.std(samp), beta_n)\n",
    "#x,y = az.kde(samp)\n",
    "#print(x[np.argmax(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## prior for beta is set such that R is roughly centered around 1 while still allowing values > 4\n",
    "## if alpha or gamma changes, relationship btw R and beta changes\n",
    "## -- set beta_prior_exp to a value that gives R = 1\n",
    "##\n",
    "def model_wrev(mdict, data_ok, beta_prior_exp = 0.2):\n",
    "\n",
    "    alpha = deterministic(\"alpha\", mdict['alpha'])\n",
    "    mu = deterministic(\"mu\", mdict['mu'])\n",
    "    gamma2 = deterministic(\"gamma2\", mdict['gamma2'])\n",
    "    gamma1 = deterministic(\"gamma1\", mdict['gamma1'])\n",
    "\n",
    "    ## gamma(2,5) prior ## (ref Karimizadeh 2023)\n",
    "    beta_conc = 5.0 #9.0 \n",
    "    beta_n = 1.0 + beta_prior_exp * beta_conc #1.0 + beta_prior_exp * (1.0 + beta_conc)\n",
    "\n",
    "    #using basis splines for beta\n",
    "    beta_mean = sample(\"beta_mean\", dist.Gamma(beta_n,beta_conc), sample_shape=(mdict['nperiods'],))\n",
    "    beta = deterministic(\"beta\", mdict['spline'] @ beta_mean)\n",
    "    \n",
    "    ## generalized logistic for theta\n",
    "    th0 = sample(\"th0\", Norm(logit(0.1), 4.0))\n",
    "    #th_min = sample(\"th_min\", dist.Beta(0.20,2.0))\n",
    "    dth_dt = sample(\"dth_dt\", dist.HalfNormal(0.2)) ##constrain to be increasing\n",
    "    th_max = sample(\"th_max\", dist.Beta(2.0,2.0))\n",
    "    #th_x0 = sample(\"th_x0\", dist.Gamma(3.0,0.1))\n",
    "    #th_shape = sample(\"th_shape\", dist.LogNormal(0.0,0.7))\n",
    "    theta = deterministic(\"theta\", th_max * logistic(th0 + mdict['tdom']*dth_dt))\n",
    "    #theta = deterministic(\"theta\", th_min + (th_max - th_min) * logistic(dth_dt * (mdict['tdom'] - th_x0 )) )\n",
    "    #theta = deterministic(\"theta\", th_max * np.power(1.0 + np.exp(-th0 - mdict['tdom']*dth_dt), -th_shape))\n",
    "\n",
    "    i0 = deterministic(\"i0\", mdict['initInfected'])\n",
    "    e0 = deterministic(\"e0\", 0.0)\n",
    "    ## c0 should be approx i0/theta\n",
    "    #c0 = deterministic(\"c0\", i0 / theta[0])\n",
    "    log_init = sample(\"log_init\", Norm(4.0, 4.0)) ##helps sampling to leave c0 free\n",
    "    c0 = deterministic(\"c0\", np.exp(log_init))\n",
    "    psize = mdict['Population']\n",
    "    y0 = np.stack([psize - (e0 + i0 + c0), e0, c0, i0, 0.0, c0, i0])\n",
    "\n",
    "    p_t = np.stack([alpha, beta, mu, gamma1, gamma2, theta]).T #transpose so time is first axis\n",
    "    pred_vals = jax.lax.scan(onestep, y0, p_t)[1] #see explanation in onestep() above\n",
    "    pred_daily = np.diff(pred_vals[:,6], prepend=0)\n",
    "    pred_ok = pred_daily[data_ok] / mdict['totalI']\n",
    "\n",
    "    ## seroreversion (time from seroconversion): Weibull shape 2.32, scale 202.20 (Brazeau et al 2022)\n",
    "    #rev_k = sample(\"rev_k\", dist.Gamma(9.28,4.0)) # Norm(2.32, 1.0))\n",
    "    rev_k = deterministic(\"rev_k\", 2.32) ## assume fixed? (1 = exponential dist)\n",
    "    rev_L = sample(\"rev_L\", Norm(202.20, 10.0))\n",
    "    ## if using non-fixed k, parameterize using mean instead of scale (easier priors)\n",
    "    #rev_mean = sample(\"rev_mean\", Norm(179.15, 20.0))\n",
    "    #rev_L = np.maximum(1e-6, rev_mean / np.exp(gammaln(1.0 + 1.0 / rev_k)) )\n",
    "\n",
    "    ## precompute reversion curves for each day in the testing period\n",
    "    rev_curve = np.flip(np.exp(-np.power( np.arange(300.) / rev_L, rev_k)))\n",
    "    rev_mat = np.flip( jax.lax.map(lambda i: np.roll(rev_curve,i), -1*np.arange(300)) , axis=0 ) * np.tri(300)\n",
    "    ## p detectable as function of time (days)\n",
    "    true_p_inf = mdict[\"DailyCases\"][:300] / (theta[:300] * psize)\n",
    "    detectable_by_day = np.nansum(true_p_inf * rev_mat , axis=1)\n",
    "\n",
    "    ## p = detectable_by_day[MD_dict[\"sero_date_idxs\"]]\n",
    "    ## obs = MD_dict[\"seropos\"]\n",
    "    ## weights = MD_dict[\"sero_weights\"]\n",
    "    with pn.plate(\"sero_data\", len(MD_dict[\"seropos\"])), pn.handlers.scale(scale=MD_dict[\"sero_weights\"]):\n",
    "        sample(\"sero\", dist.Bernoulli(detectable_by_day[MD_dict[\"sero_date_idxs\"]]), obs=MD_dict[\"seropos\"])\n",
    "\n",
    "    sigma = sample(\"sigma\", dist.Exponential(1.0))\n",
    "    nu = sample(\"xnu\", dist.Gamma(4.0,1.0)) ## df should be < 10 for robustness\n",
    "    #nu = 5.0 ## fixed for now\n",
    "    #sample(\"daily\", dist.StudentT(nu, pred_ok, sigma), obs=mdict['daily_ok'])\n",
    "    eps = 1.0 / psize\n",
    "    sample(\"daily\", dist.StudentT(nu, np.log(eps+pred_ok), sigma), obs=np.log(eps+mdict['daily_ok']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## prior for beta is set such that R is roughly centered around 1 while still allowing values > 4\n",
    "## if alpha or gamma changes, relationship btw R and beta changes\n",
    "## -- set beta_prior_exp to a value that gives R = 1\n",
    "##\n",
    "def model_exprev(mdict, data_ok, beta_prior_exp = 0.2):\n",
    "\n",
    "    alpha = deterministic(\"alpha\", mdict['alpha'])\n",
    "    mu = deterministic(\"mu\", mdict['mu'])\n",
    "    gamma2 = deterministic(\"gamma2\", mdict['gamma2'])\n",
    "    gamma1 = deterministic(\"gamma1\", mdict['gamma1'])\n",
    "\n",
    "    ## gamma(2,5) prior ## (ref Karimizadeh 2023)\n",
    "    beta_conc = 5.0 #9.0 \n",
    "    beta_n = 1.0 + beta_prior_exp * beta_conc #1.0 + beta_prior_exp * (1.0 + beta_conc)\n",
    "\n",
    "    #using basis splines for beta\n",
    "    beta_mean = sample(\"beta_mean\", dist.Gamma(beta_n,beta_conc), sample_shape=(mdict['nperiods'],))\n",
    "    beta = deterministic(\"beta\", mdict['spline'] @ beta_mean)\n",
    "    \n",
    "    ## generalized logistic for theta\n",
    "    th0 = sample(\"th0\", Norm(logit(0.1), 4.0))\n",
    "    #th_min = sample(\"th_min\", dist.Beta(0.20,2.0))\n",
    "    dth_dt = sample(\"dth_dt\", dist.HalfNormal(0.2)) ##constrain to be increasing\n",
    "    th_max = sample(\"th_max\", dist.Beta(2.0,2.0))\n",
    "    #th_x0 = sample(\"th_x0\", dist.Gamma(3.0,0.1))\n",
    "    #th_shape = sample(\"th_shape\", dist.LogNormal(0.0,0.7))\n",
    "    theta = deterministic(\"theta\", th_max * logistic(th0 + mdict['tdom']*dth_dt))\n",
    "    #theta = deterministic(\"theta\", th_min + (th_max - th_min) * logistic(dth_dt * (mdict['tdom'] - th_x0 )) )\n",
    "    #theta = deterministic(\"theta\", th_max * np.power(1.0 + np.exp(-th0 - mdict['tdom']*dth_dt), -th_shape))\n",
    "\n",
    "    i0 = deterministic(\"i0\", mdict['initInfected'])\n",
    "    e0 = deterministic(\"e0\", 0.0)\n",
    "    ## c0 should be approx i0/theta\n",
    "    #c0 = deterministic(\"c0\", i0 / theta[0])\n",
    "    log_init = sample(\"log_init\", Norm(4.0, 4.0)) ##helps sampling to leave c0 free\n",
    "    c0 = deterministic(\"c0\", np.exp(log_init))\n",
    "    psize = mdict['Population']\n",
    "    y0 = np.stack([psize - (e0 + i0 + c0), e0, c0, i0, 0.0, c0, i0])\n",
    "\n",
    "    p_t = np.stack([alpha, beta, mu, gamma1, gamma2, theta]).T #transpose so time is first axis\n",
    "    pred_vals = jax.lax.scan(onestep, y0, p_t)[1] #see explanation in onestep() above\n",
    "    pred_daily = np.diff(pred_vals[:,6], prepend=0)\n",
    "    pred_ok = pred_daily[data_ok] / mdict['totalI']\n",
    "\n",
    "    ## seroreversion (time from seroconversion): exponential rate = 0.0057 (0.0051–0.0063) Chen et al 2021\n",
    "    rev_L = sample(\"rev_L\", Norm(0.0057, 0.0003))\n",
    "\n",
    "    ## precompute reversion curves for each day in the testing period\n",
    "    rev_curve = np.flip( np.exp(-rev_L * np.arange(300.)) )\n",
    "    rev_mat = np.flip( jax.lax.map(lambda i: np.roll(rev_curve,i), -1*np.arange(300)) , axis=0 ) * np.tri(300)\n",
    "    ## p detectable as function of time (days)\n",
    "    true_p_inf = mdict[\"DailyCases\"][:300] / (theta[:300] * psize)\n",
    "    detectable_by_day = np.nansum(true_p_inf * rev_mat , axis=1)\n",
    "\n",
    "    ## p = detectable_by_day[MD_dict[\"sero_date_idxs\"]]\n",
    "    ## obs = MD_dict[\"seropos\"]\n",
    "    ## weights = MD_dict[\"sero_weights\"]\n",
    "    with pn.plate(\"sero_data\", len(MD_dict[\"seropos\"])), pn.handlers.scale(scale=MD_dict[\"sero_weights\"]):\n",
    "        sample(\"sero\", dist.Bernoulli(detectable_by_day[MD_dict[\"sero_date_idxs\"]]), obs=MD_dict[\"seropos\"])\n",
    "\n",
    "    sigma = sample(\"sigma\", dist.Exponential(1.0))\n",
    "    nu = sample(\"xnu\", dist.Gamma(4.0,1.0)) ## df should be < 10 for robustness\n",
    "    #nu = 5.0 ## fixed for now\n",
    "    #sample(\"daily\", dist.StudentT(nu, pred_ok, sigma), obs=mdict['daily_ok'])\n",
    "    eps = 1.0 / psize\n",
    "    sample(\"daily\", dist.StudentT(nu, np.log(eps+pred_ok), sigma), obs=np.log(eps+mdict['daily_ok']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_norev(mdict, data_ok, beta_prior_exp = 0.2):\n",
    "\n",
    "    alpha = deterministic(\"alpha\", mdict['alpha'])\n",
    "    mu = deterministic(\"mu\", mdict['mu'])\n",
    "    gamma2 = deterministic(\"gamma2\", mdict['gamma2'])\n",
    "    gamma1 = deterministic(\"gamma1\", mdict['gamma1'])\n",
    "\n",
    "    ## gamma(2,5) prior ## (ref Karimizadeh 2023)\n",
    "    beta_conc = 5.0 #9.0 \n",
    "    beta_n = 1.0 + beta_prior_exp * beta_conc #1.0 + beta_prior_exp * (1.0 + beta_conc)\n",
    "\n",
    "    #using basis splines for beta\n",
    "    beta_mean = sample(\"beta_mean\", dist.Gamma(beta_n,beta_conc), sample_shape=(mdict['nperiods'],))\n",
    "    beta = deterministic(\"beta\", mdict['spline'] @ beta_mean)\n",
    "    \n",
    "    ## generalized logistic for theta\n",
    "    th0 = sample(\"th0\", Norm(logit(0.1), 4.0))\n",
    "    #th_min = sample(\"th_min\", dist.Beta(0.20,2.0))\n",
    "    dth_dt = sample(\"dth_dt\", dist.HalfNormal(0.2)) ##constrain to be increasing\n",
    "    th_max = sample(\"th_max\", dist.Beta(2.0,2.0))\n",
    "    #th_x0 = sample(\"th_x0\", dist.Gamma(3.0,0.1))\n",
    "    #th_shape = sample(\"th_shape\", dist.LogNormal(0.0,0.7))\n",
    "    theta = deterministic(\"theta\", th_max * logistic(th0 + mdict['tdom']*dth_dt))\n",
    "    #theta = deterministic(\"theta\", th_min + (th_max - th_min) * logistic(dth_dt * (mdict['tdom'] - th_x0 )) )\n",
    "    #theta = deterministic(\"theta\", th_max * np.power(1.0 + np.exp(-th0 - mdict['tdom']*dth_dt), -th_shape))\n",
    "\n",
    "    i0 = deterministic(\"i0\", mdict['initInfected'])\n",
    "    e0 = deterministic(\"e0\", 0.0)\n",
    "    ## c0 should be approx i0/theta\n",
    "    #c0 = deterministic(\"c0\", i0 / theta[0])\n",
    "    log_init = sample(\"log_init\", Norm(4.0, 4.0)) ##helps sampling to leave c0 free\n",
    "    c0 = deterministic(\"c0\", np.exp(log_init))\n",
    "    psize = mdict['Population']\n",
    "    y0 = np.stack([psize - (e0 + i0 + c0), e0, c0, i0, 0.0, c0, i0])\n",
    "\n",
    "    p_t = np.stack([alpha, beta, mu, gamma1, gamma2, theta]).T #transpose so time is first axis\n",
    "    pred_vals = jax.lax.scan(onestep, y0, p_t)[1] #see explanation in onestep() above\n",
    "    pred_daily = np.diff(pred_vals[:,6], prepend=0)\n",
    "    pred_ok = pred_daily[data_ok] / mdict['totalI']\n",
    "\n",
    "    ## p detectable as function of time (days)\n",
    "    true_p_inf = mdict[\"DailyCases\"][:300] / (theta[:300] * psize)\n",
    "    detectable_by_day = np.nancumsum(true_p_inf)\n",
    "\n",
    "    ## p = detectable_by_day[MD_dict[\"sero_date_idxs\"]]\n",
    "    ## obs = MD_dict[\"seropos\"]\n",
    "    ## weights = MD_dict[\"sero_weights\"]\n",
    "    with pn.plate(\"sero_data\", len(MD_dict[\"seropos\"])), pn.handlers.scale(scale=MD_dict[\"sero_weights\"]):\n",
    "        sample(\"sero\", dist.Bernoulli(detectable_by_day[MD_dict[\"sero_date_idxs\"]]), obs=MD_dict[\"seropos\"])\n",
    "\n",
    "    sigma = sample(\"sigma\", dist.Exponential(1.0))\n",
    "    nu = sample(\"xnu\", dist.Gamma(4.0,1.0)) ## df should be < 10 for robustness\n",
    "    #nu = 5.0 ## fixed for now\n",
    "    #sample(\"daily\", dist.StudentT(nu, pred_ok, sigma), obs=mdict['daily_ok'])\n",
    "    eps = 1.0 / psize\n",
    "    sample(\"daily\", dist.StudentT(nu, np.log(eps+pred_ok), sigma), obs=np.log(eps+mdict['daily_ok']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_models = True\n",
    "run_models = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if run_models:\n",
    "    runs_wrev = []\n",
    "    dat = {'mdict': MD_dict, 'data_ok': ok_for_jax}\n",
    "    runs_wrev.append( \n",
    "        MCMC(NUTS(model_wrev, \n",
    "        #target_accept_prob=0.88, dense_mass=True),# init_strategy=pn.infer.init_to_sample), \n",
    "        #target_accept_prob=0.9, dense_mass=True),# init_strategy=pn.infer.init_to_sample), \n",
    "        target_accept_prob=0.9, dense_mass=True, init_strategy=pn.infer.init_to_sample), \n",
    "        #target_accept_prob=0.92, dense_mass=True, init_strategy=pn.infer.init_to_sample), \n",
    "        #num_warmup=5000, num_samples=5000, num_chains=6)\n",
    "        num_warmup=2500, num_samples=2500, num_chains=4)\n",
    "        #num_warmup=1000, num_samples=500, num_chains=6)\n",
    "    )\n",
    "    runs_wrev[-1].run(key(), **dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store(runs_wrev[0], \"slag\"+str(seroconv_lag)+\"_2500x4_0\")\n",
    "runs_wrev = [load(\"slag\"+str(seroconv_lag)+\"_2500x4_0\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if run_models:\n",
    "    runs_exprev = []\n",
    "    dat = {'mdict': MD_dict, 'data_ok': ok_for_jax}\n",
    "    runs_exprev.append( \n",
    "        MCMC(NUTS(model_exprev, \n",
    "        #target_accept_prob=0.88, dense_mass=True),# init_strategy=pn.infer.init_to_sample), \n",
    "        #target_accept_prob=0.9, dense_mass=True),# init_strategy=pn.infer.init_to_sample), \n",
    "        target_accept_prob=0.9, dense_mass=True, init_strategy=pn.infer.init_to_sample), \n",
    "        #target_accept_prob=0.92, dense_mass=True, init_strategy=pn.infer.init_to_sample), \n",
    "        #num_warmup=5000, num_samples=5000, num_chains=6)\n",
    "        num_warmup=2500, num_samples=2500, num_chains=4)\n",
    "        #num_warmup=1000, num_samples=500, num_chains=6)\n",
    "    )\n",
    "    runs_exprev[-1].run(key(), **dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store(runs_exprev[0],'exprev_2500x4_0')\n",
    "runs_exprev = [load(\"exprev_2500x4_0\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if run_models:\n",
    "    runs_norev = []\n",
    "    dat = {'mdict': MD_dict, 'data_ok': ok_for_jax}\n",
    "    runs_norev.append( \n",
    "        MCMC(NUTS(model_norev, \n",
    "        #target_accept_prob=0.88, dense_mass=True),# init_strategy=pn.infer.init_to_sample), \n",
    "        #target_accept_prob=0.9, dense_mass=True),# init_strategy=pn.infer.init_to_sample), \n",
    "        target_accept_prob=0.9, dense_mass=True, init_strategy=pn.infer.init_to_sample), \n",
    "        #target_accept_prob=0.92, dense_mass=True, init_strategy=pn.infer.init_to_sample), \n",
    "        #num_warmup=5000, num_samples=5000, num_chains=6)\n",
    "        num_warmup=2500, num_samples=2500, num_chains=4)\n",
    "        #num_warmup=1000, num_samples=500, num_chains=6)\n",
    "    )\n",
    "    runs_norev[-1].run(key(), **dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store(runs_norev[0],'norev_2500x4_0')\n",
    "#runs_norev = [load(\"norev_2500x4_0\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_model = runs_norev[0]\n",
    "#model_str = \"norev\"\n",
    "#use_model = runs_exprev[0]\n",
    "#model_str = \"exprev\"\n",
    "use_model = runs_wrev[0]\n",
    "model_str = \"slag\"+str(seroconv_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(use_model,var_names=['th0', 'th_max', 'dth_dt', 'c0', 'xnu', 'sigma', 'rev_L'])\n",
    "#az.summary(use_model,var_names=['th0', 'th_max', 'dth_dt', 'c0', 'xnu', 'sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(use_model,var_names=['th0', 'th_max', 'dth_dt', 'log_init', 'xnu', 'sigma', 'rev_L']);\n",
    "#az.plot_trace(use_model,var_names=['th0', 'th_max', 'dth_dt', 'log_init', 'xnu', 'sigma']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop a chain\n",
    "#az_obj = az.from_numpyro(use_model)\n",
    "#az.plot_trace(az_obj.sel(chain=[0]),var_names=model_var_names);\n",
    "#az_obj = az_obj.sel(chain=[2,3,4,5])\n",
    "#az.summary(az_obj,var_names=model_var_names)\n",
    "#ds_post = az_obj.posterior.stack({\"sample\": [\"chain\",\"draw\"]}).transpose()\n",
    "#post = {k:arr(ds_post[k].values) for k in ds_post.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = use_model.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0 / post['rev_L'].mean(0), 1.0 / hpdi(post['rev_L'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df, sim_cols = df_samples(post,MD_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1,figsize=[5,7],dpi=300)\n",
    "for c in sim_cols:\n",
    "    ax[0].plot(df[c], color='orangered', alpha=0.25)\n",
    "\n",
    "sns.lineplot(ax=ax[0],data=df,x=\"Date\",y=\"DailyCases\",color=\"0.3\")\n",
    "sns.lineplot(ax=ax[1],data=df,x=\"Date\",y=\"R_t\",color=\"0.3\")\n",
    "sns.despine()\n",
    "\n",
    "ax[1].fill_between(df[\"Date\"],df[\"R_t_lower95\"],df[\"R_t_upper95\"],alpha=0.33,color='0.3')\n",
    "ax[0].set(ylim=(0,4000), xlabel=None, ylabel='Daily cases')\n",
    "ax[1].set(ylim=(-0.18,6.9), xlabel=None, ylabel='R(t)')\n",
    "fig.subplots_adjust(hspace=0.25)\n",
    "\n",
    "for x in ax:\n",
    "    x.set_xticks(x.get_xticks()[::50]);\n",
    "    x.set_xticklabels(x.get_xticklabels(), rotation=30, horizontalalignment='right');\n",
    "\n",
    "plt.savefig(model_str+\" sero_Rt.png\", bbox_inches='tight',dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[5,4],dpi=300)\n",
    "sns.lineplot(ax=ax,data=df,x=\"Date\",y=\"theta\",color=\"0.3\")\n",
    "sns.despine()\n",
    "\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "\n",
    "ci = hpdi(post['theta'])\n",
    "ax.fill_between(df[\"Date\"],ci[0,:],ci[1,:],alpha=0.33,color=\"0.3\")\n",
    "ax.set(ylim=(0,0.55),ylabel='reporting rate',xlabel=None)\n",
    "ax.set_xticks(ax.get_xticks()[::50]);\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=30, horizontalalignment='right');\n",
    "\n",
    "plt.savefig(model_str+\" sero_theta.png\",bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pred_daily_samp(post,MD_dict,2000)\n",
    "pred_samp = x.mean(0)\n",
    "obs = MD_dict['DailyCases']\n",
    "resid = pred_samp - obs\n",
    "## pseudo-R2 (there are better measures of this)\n",
    "1.0 - np.var(resid) / np.var(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 10\n",
    "fig,ax=plt.subplots(figsize=[5,4],dpi=300)\n",
    "\n",
    "sns.scatterplot(data=pd.DataFrame(data={\"beta\":5.0*post['beta'][0:2000,t], \"theta\":post['theta'][0:2000,t]}),\n",
    "    x=\"beta\",y=\"theta\",alpha=0.25,color=\"0.1\")\n",
    "sns.despine()\n",
    "\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "\n",
    "ax.set(xlim=(0.6,6.8), ylim=(-0.04,0.55), xlabel=f'R (t = {t})' ,ylabel=f'reporting rate (t = {t})')\n",
    "az.plot_kde(5.0*post['beta'][0:2000,t], post['theta'][0:2000,t], hdi_probs=[0.5,0.9], ax=ax, \n",
    "    contourf_kwargs={'alpha':0}, contour_kwargs={'colors':[\"0.9\",\"0.3\"]})\n",
    "\n",
    "plt.savefig(model_str+\" sero_joint.png\",bbox_inches='tight',dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_total_daily = pred_daily_samp(post, MD_dict, 5000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"inf_total\"] = pred_total_daily.mean(0)\n",
    "ci = hpdi(pred_total_daily)\n",
    "df[\"inf_total_L\"] = ci[0]\n",
    "df[\"inf_total_H\"] = ci[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[5,4],dpi=300)\n",
    "sns.lineplot(ax=ax,data=df,x=\"Date\",y=\"inf_total\",color=\"0.3\")\n",
    "sns.lineplot(ax=ax,data=df,x=\"Date\",y=\"DailyCases\",color=\"orangered\")\n",
    "sns.despine()\n",
    "\n",
    "ax.fill_between(df[\"Date\"],df[\"inf_total_L\"],df[\"inf_total_H\"],alpha=0.33,color=\"0.3\")\n",
    "ax.set(ylabel='total daily infected',xlabel=None)\n",
    "ax.set_xticks(ax.get_xticks()[::50]);\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=30, horizontalalignment='right');\n",
    "\n",
    "plt.savefig(model_str+\" sero_total_infected.png\",bbox_inches='tight',dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(pd.Series(arr(MD_deaths.loc['2020-03-04':,'daily_deaths'])).rename(\"daily_deaths\"))\n",
    "df[\"true_daily\"] = df[\"DailyCases\"] / df[\"theta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 14\n",
    "plt.plot(df[\"true_daily\"].values[:-lag]);\n",
    "plt.plot(df[\"DailyCases\"].values[:-lag]);\n",
    "plt.plot(60 * df[\"daily_deaths\"].values[lag:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_deaths = arr(MD_deaths.loc['2020-03-04':,'daily_deaths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_r = 5.6\n",
    "nb_p = 0.2857\n",
    "xlen = daily_deaths.shape[0]\n",
    "p_dist = stats.nbinom.pmf(np.arange(xlen), nb_r, nb_p).round(6)\n",
    "\n",
    "future_deaths = arr([np.nansum(daily_deaths * p_dist), \n",
    "    *[np.nansum(daily_deaths[i:] * p_dist[:-i]) for i in range(1,xlen-60)]])\n",
    "\n",
    "future_deaths = future_deaths[:MD_dict['tdom'].shape[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_fatality = future_deaths / pred_total_daily\n",
    "ci = hpdi(prob_fatality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(pd.DataFrame({\"prob_fatality\":prob_fatality.mean(0), \"prob_fatality_L\":ci[0], \"prob_fatality_H\":ci[1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## very noisy at beginning\n",
    "df_plot = df.iloc[18:-5,:]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[4,6],dpi=300)\n",
    "sns.lineplot(ax=ax,data=df_plot,x=\"Date\",y=\"prob_fatality\",color=\"0.3\")\n",
    "sns.despine()\n",
    "\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "\n",
    "ax.fill_between(df_plot[\"Date\"],df_plot[\"prob_fatality_L\"],df_plot[\"prob_fatality_H\"],alpha=0.33,color=\"0.3\")\n",
    "ax.set(ylabel='infection fatality rate',xlabel=None,ylim=(-0.002,0.05))\n",
    "ax.set_yticks(ax.get_yticks()[1::1]);\n",
    "ax.set_xticks(ax.get_xticks()[::60]);\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=30, horizontalalignment='right');\n",
    "\n",
    "plt.savefig(model_str+\" prob infection_fatality.png\",bbox_inches='tight',dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pyro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa5661dc2b784affb91f2bbcf97c0fc07b3941d8cb5fd98c997fe8e105d91386"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
